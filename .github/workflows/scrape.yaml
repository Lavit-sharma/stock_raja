name: TradingView Scraper (Parallel 10x, 50-row batching)

on:
  schedule:
    - cron: '0 1 * * *' # UTC schedule (~06:30 AM IST)
  workflow_dispatch:
    inputs:
      total_batches:
        description: 'Number of parallel batches'
        required: false
        default: '10'
      batch_size:
        description: 'Companies per batch'
        required: false
        default: '200'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    strategy:
      fail-fast: false
      matrix:
        shard: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # 10 parallel shards
      max-parallel: 10

    env:
      SHARD_INDEX: ${{ matrix.shard }}                 # modulus sharding still available
      SHARD_STEP:  ${{ inputs.total_batches || '10' }} # 10 shards by default

    steps:
      - name: â¬‡ï¸ Checkout Repository
        uses: actions/checkout@v4

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: ðŸŒ Install Chrome (fast)
        run: |
          set -e
          curl -fsSL "https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb" -o chrome.deb
          sudo dpkg -i chrome.deb || sudo apt-get -f install -y
          google-chrome --version || true  # verify install

      - name: ðŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium beautifulsoup4 gspread webdriver-manager

      - name: ðŸ”‘ Set up Google Credentials
        run: echo '${{ secrets.GSPREAD_CREDENTIALS }}' > credentials.json

      - name: ðŸª Set up TradingView Cookies
        run: echo '${{ secrets.TRADINGVIEW_COOKIES }}' > cookies.json

      - name: ðŸ”¢ Calculate range (10x200)
        id: calc
        shell: bash
        env:
          MATRIX_BATCH:  ${{ matrix.shard }}                 # 0..9
          BATCH_SIZE:    ${{ inputs.batch_size   || '200' }} # 200
        run: |
          # Convert 0-based shard to 1-based batches for range math
          BATCH_NUM=$(( ${MATRIX_BATCH} + 1 ))
          START=$(( ( ${BATCH_NUM} - 1 ) * ${BATCH_SIZE} + 1 ))
          echo "start=${START}" >> "$GITHUB_OUTPUT"
          echo "size=${BATCH_SIZE}" >> "$GITHUB_OUTPUT"
          # Gentle stagger to smooth read/write bursts
          SLEEP=$(( ${BATCH_NUM} * 10 ))  # 10s,20s,...,100s
          echo "sleep=${SLEEP}" >> "$GITHUB_OUTPUT"

      - name: â³ Stagger start
        shell: bash
        run: |
          echo "Staggering ${{ steps.calc.outputs.sleep }}s"
          sleep "${{ steps.calc.outputs.sleep }}"

      - name: ðŸš€ Run Scraper Script
        env:
          CHECKPOINT_FILE: checkpoint_new_1_${{ matrix.shard }}.txt
          START_INDEX:  ${{ steps.calc.outputs.start }}  # direct range mode
          BATCH_SIZE:   ${{ steps.calc.outputs.size }}
          SHARD_INDEX:  ${{ env.SHARD_INDEX }}           # still exported for modulus path
          SHARD_STEP:   ${{ env.SHARD_STEP }}
        run: |
          FILE="$CHECKPOINT_FILE"
          if [ ! -f "$FILE" ]; then echo "1" > "$FILE"; fi
          echo "Shard ${{ matrix.shard }} â†’ START_INDEX=$START_INDEX, BATCH_SIZE=$BATCH_SIZE"
          python run_scraper.py
