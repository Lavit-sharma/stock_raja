name: Daily Stock Scraper

on:
  schedule:
    - cron: '30 3 * * *'
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of companies'
        required: false
        default: '100'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install Chrome
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
      
      - name: Install Python packages
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run scraper
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
          TRADINGVIEW_EMAIL: ${{ secrets.TRADINGVIEW_EMAIL }}
          TRADINGVIEW_PASSWORD: ${{ secrets.TRADINGVIEW_PASSWORD }}
          BATCH_SIZE: ${{ github.event.inputs.batch_size || '100' }}
          START_INDEX: '1'
        run: |
          python run_scraper.py
      
      - name: Upload logs (if failed)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: error-logs
          path: |
            *.log
            *.html
