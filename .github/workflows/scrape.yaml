name: TradingView Scraper (Parallel 10x)

on:
  schedule:
    - cron: '30 3 * * *'   # 09:00 AM IST (UTC+5:30)
  workflow_dispatch:
    inputs:
      total_batches:
        description: 'Number of parallel batches'
        required: false
        default: '10'
      batch_size:
        description: 'Companies per batch'
        required: false
        default: '200'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    strategy:
      matrix:
        batch: [1,2,3,4,5,6,7,8,9,10]
      max-parallel: 10

    steps:
      - name: â¬‡ï¸ Checkout Repository
        uses: actions/checkout@v3

      - name: ðŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: ðŸ§­ Install Chrome
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: ðŸ“¦ Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium beautifulsoup4 gspread webdriver-manager oauth2client

      - name: ðŸ”‘ Set up Google Credentials
        run: echo '${{ secrets.GSPREAD_CREDENTIALS }}' > credentials.json

      - name: ðŸš€ Run Scraper Batch ${{ matrix.batch }}
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GSPREAD_CREDENTIALS }}
          START_INDEX: ${{ (matrix.batch - 1) * fromJSON(github.event.inputs.batch_size || '200') + 1 }}
          BATCH_SIZE: ${{ github.event.inputs.batch_size || '200' }}
        run: |
          echo "Batch ${{ matrix.batch }} started: START_INDEX=${{ env.START_INDEX }}, BATCH_SIZE=${{ env.BATCH_SIZE }}"
          python run_scraper.py
