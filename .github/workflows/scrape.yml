name: Parallel Stock Scraper (Logged-In, 10x Parallel)

on:
  schedule:
    - cron: '30 3 * * *' # Daily at 03:30 UTC
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        batch: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # 10 parallel batches
      max-parallel: 10
      fail-fast: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Show commit SHA
        run: echo "Running commit ${{ github.sha }}"

      - name: Install Chrome
        run: |
          set -e
          curl -fsSL "https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb" -o chrome.deb
          sudo dpkg -i chrome.deb || sudo apt-get -f install -y
          google-chrome --version || true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gspread selenium beautifulsoup4 google-api-core packaging

      - name: Calculate start index
        id: calc
        shell: bash
        env:
          MATRIX_BATCH: ${{ matrix.batch }}
        run: |
          START=$(( ( ${MATRIX_BATCH} - 1 ) * 200 + 1 ))   # 1, 201, 401, ...
          echo "start=${START}" >> "$GITHUB_OUTPUT"
          echo "size=200" >> "$GITHUB_OUTPUT"

      - name: Stagger start
        shell: bash
        env:
          MATRIX_BATCH: ${{ matrix.batch }}
        run: |
          SLEEP=$(( ( ${MATRIX_BATCH} - 1 ) * 10 ))  # 0s,10s,20s... smooth load
          echo "Staggering ${SLEEP}s"
          sleep "${SLEEP}"

      - name: Run batch
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
          COOKIES_JSON: ${{ secrets.COOKIES_JSON }}
          START_INDEX: ${{ steps.calc.outputs.start }}
          BATCH_SIZE: ${{ steps.calc.outputs.size }}
        run: |
          echo "Batch ${{ matrix.batch }}: START_INDEX=$START_INDEX, SIZE=$BATCH_SIZE"
          python run_scraper.py

