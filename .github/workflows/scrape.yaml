name: TradingView Scraper (Parallel 10x)

on:
  schedule:
    - cron: '30 3 * * *'   # 9:00 AM IST
  workflow_dispatch:
    inputs:
      total_batches:
        description: 'Number of parallel batches'
        required: false
        default: '10'
      batch_size:
        description: 'Companies per batch'
        required: false
        default: '200'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    strategy:
      matrix:
        batch: [1,2,3,4,5,6,7,8,9,10]
      max-parallel: 10

    steps:
      - name: â¬‡ï¸ Checkout Repository
        uses: actions/checkout@v4

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: ðŸ“¦ Install Dependencies
        run: |
          pip install selenium beautifulsoup4 gspread webdriver-manager

      - name: ðŸ”‘ Create Google Credentials
        run: echo '${{ secrets.GSPREAD_CREDENTIALS }}' > credentials.json

      - name: ðŸª Create TradingView Cookies
        run: echo '${{ secrets.TRADINGVIEW_COOKIES }}' > cookies.json

      - name: ðŸš€ Run Scraper Batch ${{ matrix.batch }}
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GSPREAD_CREDENTIALS }}
          MATRIX_BATCH: ${{ matrix.batch }}
          INPUT_BATCH_SIZE: ${{ github.event.inputs.batch_size }}
        run: |
          echo "Running batch $MATRIX_BATCH with batch size $INPUT_BATCH_SIZE"
          python run_scraper.py
