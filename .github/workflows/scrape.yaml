name: TradingView Scraper

on:
  schedule:
    - cron: '0 1 * * *'
  workflow_dispatch:

jobs:
  prepare_data:
    name: Prepare Stock List
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - run: pip install gspread

      - run: echo '${{ secrets.GSPREAD_CREDENTIALS }}' > credentials.json

      - run: python prepare_data.py

      - uses: actions/upload-artifact@v4
        with:
          name: stock-data
          path: |
            company_list.json
            name_list.json

  scrape:
    needs: prepare_data
    strategy:
      fail-fast: false
      matrix:
        chunk: [1,2,3,4,5,6,7,8,9,10]
        chunk_size: [250]
        start_index: [1]
    name: Scrape Chunk ${{ matrix.chunk }}/10
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          name: stock-data
          path: .

      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - run: pip install selenium beautifulsoup4 gspread webdriver-manager

      - run: echo '${{ secrets.GSPREAD_CREDENTIALS }}' > credentials.json
      - run: echo '${{ secrets.TRADINGVIEW_COOKIES }}' > cookies.json

      - id: indices
        run: |
          ZERO_BASED_CHUNK=$(( ${{ matrix.chunk }} - 1 ))
          START=$(( ${{ matrix.start_index }} + (ZERO_BASED_CHUNK * ${{ matrix.chunk_size }}) ))
          END=$(( START + ${{ matrix.chunk_size }} - 1 ))
          echo "CHUNK_START_INDEX=$START" >> $GITHUB_ENV
          echo "CHUNK_END_INDEX=$END" >> $GITHUB_ENV

      - run: echo "${{ env.CHUNK_START_INDEX }}" > checkpoint_new_1.txt
      - run: python run_scraper.py
