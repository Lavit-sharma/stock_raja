name: TradingView Scraper

on:
  schedule:
    - cron: '0 1 * * *' # Runs daily at 01:00 UTC
  workflow_dispatch:   # Allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        shard: [0,1,2,3,4,5,6,7,8,9]
      # Optional: limit parallel runs if Google Sheets 429s occur
      # max-parallel: 5
    env:
      SHARD_INDEX: ${{ matrix.shard }}
      SHARD_STEP: 10

    steps:
      - name: â¬‡ï¸ Checkout Repository
        uses: actions/checkout@v4

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: ðŸ“¦ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium beautifulsoup4 gspread webdriver-manager

      - name: ðŸ”‘ Set up Google Credentials
        run: |
          echo "${{ secrets.GSPREAD_CREDENTIALS }}" > credentials.json
        shell: bash

      - name: ðŸª Set up TradingView Cookies
        run: |
          echo "${{ secrets.TRADINGVIEW_COOKIES }}" > cookies.json
        shell: bash

      - name: âš™ï¸ Create Checkpoint File (matrix-aware)
        run: |
          FILE="checkpoint_new_1_${{ matrix.shard }}.txt"
          if [ ! -f "$FILE" ]; then
            echo "1" > "$FILE"
          fi
        shell: bash

      - name: ðŸš€ Run Scraper Script
        env:
          CHECKPOINT_FILE: checkpoint_new_1_${{ matrix.shard }}.txt
          GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/credentials.json
        run: python run_scraper.py
        shell: bash
