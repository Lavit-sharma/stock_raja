name: Parallel Stock Scraper (Logged-In, 10x Parallel)

on:
  schedule:
    - cron: '30 3 * * *'  # Daily at 03:30 UTC (adjust as needed)
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        batch: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # 10 jobs Ã— 200 = 2000
      max-parallel: 10

    steps:
      - name: Checkout
        uses: actions/checkout@v4  # latest stable

      - name: Show commit SHA
        run: echo "Running commit ${{ github.sha }}"  # verify code version

      - name: Install Chrome (fast)
        run: |
          set -e
          curl -fsSL https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb -o chrome.deb
          sudo dpkg -i chrome.deb || sudo apt-get -f install -y
          google-chrome --version || true  # confirm install

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'  # runner-supported

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt  # selenium, bs4, gspread, etc.

      - name: Calculate range
        id: calc
        shell: bash
        env:
          MATRIX_BATCH: ${{ matrix.batch }}
        run: |
          echo "start=$(( ( ${MATRIX_BATCH} - 1 ) * 200 + 1 ))" >> "$GITHUB_OUTPUT"  # 1,201,401,...

      - name: Stagger start
        shell: bash
        env:
          MATRIX_BATCH: ${{ matrix.batch }}
        run: |
          SLEEP=$(( (${MATRIX_BATCH} - 1) * 10 ))  # 0s,10s,20s... to smooth load
          echo "Staggering ${SLEEP}s"
          sleep "${SLEEP}"

      - name: Run batch
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}  # Sheets auth
          COOKIES_JSON: ${{ secrets.COOKIES_JSON }}              # TradingView session cookies
          START_INDEX: ${{ steps.calc.outputs.start }}           # computed start
          BATCH_SIZE: '200'                                      # 200 per job
        run: |
          echo "Batch ${{ matrix.batch }}: START_INDEX=$START_INDEX, SIZE=$BATCH_SIZE"
          python run_scraper.py  # always-login scraper
