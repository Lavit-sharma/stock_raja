name: Parallel Stock Scraper (Logged-In)

on:
schedule:
- cron: '30 3 * * *' # Daily run; change timing if neededâ€‹
workflow_dispatch:

jobs:
scrape:
runs-on: ubuntu-latest
timeout-minutes: 90

text
strategy:
  matrix:
    batch: 
  max-parallel: 10

steps:
  - name: Checkout
    uses: actions/checkout@v3  # Pulls exact code for this run[1]

  - name: Show commit SHA
    run: echo "Running commit ${{ github.sha }}"  # Verify code parity[2]

  - name: Install Chrome (fast)
    run: |
      set -e
      curl -fsSL https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb -o chrome.deb
      sudo dpkg -i chrome.deb || sudo apt-get -f install -y
      google-chrome --version || true  # Print version for logs [1]

  - name: Setup Python
    uses: actions/setup-python@v4
    with:
      python-version: '3.10'  # Stable on ubuntu-latest[1]

  - name: Install dependencies
    run: |
      python -m pip install --upgrade pip
      pip install -r requirements.txt  # selenium, bs4, gspread, etc.[1]

  - name: Calculate range
    id: calc
    run: |
      echo "start=$(( (${{ matrix.batch }} - 1) * 200 + 1 ))" >> $GITHUB_OUTPUT  # 200/company per job[1]

  - name: Run batch ${{ matrix.batch }}
    env:
      GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}  # Service Account JSON (string)[1]
      COOKIES_JSON: ${{ secrets.COOKIES_JSON }}              # TradingView session cookies JSON[1]
      START_INDEX: ${{ steps.calc.outputs.start }}
      BATCH_SIZE: '200'
    run: |
      echo "Batch ${{ matrix.batch }}: START_INDEX=$START_INDEX, SIZE=$BATCH_SIZE"
      python run_scraper.py  # Always-login scraper[1]
