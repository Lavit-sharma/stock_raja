name: TradingView Scraper (Parallel 10x)

on:
  schedule:
    - cron: '30 3 * * *'   # Runs daily at 09:00 AM IST (03:30 UTC)
  workflow_dispatch:
    inputs:
      total_batches:
        description: 'Number of parallel batches'
        required: false
        default: '10'
      batch_size:
        description: 'Companies per batch'
        required: false
        default: '200'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    strategy:
      matrix:
        batch: [1,2,3,4,5,6,7,8,9,10]
      max-parallel: 10

    steps:
      - name: â¬‡ï¸ Checkout Repository
        uses: actions/checkout@v4

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: ðŸ“¦ Install Dependencies
        run: |
          pip install selenium beautifulsoup4 gspread webdriver-manager

      - name: ðŸ”‘ Create Google Credentials
        run: echo '${{ secrets.GSPREAD_CREDENTIALS }}' > credentials.json

      - name: ðŸª Create TradingView Cookies
        run: echo '${{ secrets.TRADINGVIEW_COOKIES }}' > cookies.json

      - name: ðŸš€ Run Scraper Batch ${{ matrix.batch }}
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GSPREAD_CREDENTIALS }}
          TRADINGVIEW_EMAIL: ${{ secrets.TRADINGVIEW_EMAIL }}
          TRADINGVIEW_PASSWORD: ${{ secrets.TRADINGVIEW_PASSWORD }}
          START_INDEX: ${{ (matrix.batch - 1) * fromJSON(github.event.inputs.batch_size || '200') + 1 }}
          BATCH_SIZE: ${{ github.event.inputs.batch_size || '200' }}
        run: |
          echo "Batch ${{ matrix.batch }} starting..."
          python run_scraper.py
