name: Parallel Stock Scraper (Stable)

on:
  schedule:
    - cron: '30 3 * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        batch: [1,2,3,4,5,6,7,8,9,10]
      max-parallel: 10
      fail-fast: false

    steps:
      - uses: actions/checkout@v4

      - name: Install Chrome
        run: |
          sudo apt-get update
          curl -fsSL "https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb" -o chrome.deb
          sudo dpkg -i chrome.deb || sudo apt-get -f install -y

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install selenium gspread beautifulsoup4 google-api-core webdriver-manager

      - name: Compute batch
        id: calc
        run: |
          START=$(( ( ${{ matrix.batch }} - 1 ) * 200 + 1 ))
          echo "start=${START}" >> "$GITHUB_OUTPUT"
          echo "size=200" >> "$GITHUB_OUTPUT"

      - name: Delay start
        run: sleep $(( ( ${{ matrix.batch }} - 1 ) * 10 ))

      - name: Run scraper
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
          COOKIES_JSON: ${{ secrets.COOKIES_JSON }}
          START_INDEX: ${{ steps.calc.outputs.start }}
          BATCH_SIZE: ${{ steps.calc.outputs.size }}
        run: python run_scraper.py
